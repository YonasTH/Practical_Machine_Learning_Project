install.pakages(knitr)
install.packages("knitr")
install.packages("rmarkdown")
library(caret)
training <- read.csv("~/Practical Machine Learning/Course_project/pml-training.csv")
testing <- read.csv("~/Practical Machine Learning/Course_project/pml-testing.csv")
names(training)
summary(training)
length(names(training))
inTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
raw_training_cv <- training[inTrain, ]
raw_testing_cv <- training[-inTrain,]
#remove covariates with near-zero-variablity
nzv <- nearZeroVar(raw_training_cv, saveMetrics=TRUE)
raw_training_cv <- raw_training_cv[ , nzv$nzv==FALSE]
sum(nzv$nzv==TRUE) #variables are removed because they have near-zero-variablity and do not affect the prediction much
raw_testing_cv <- raw_testing_cv[ ,nzv$nzv==FALSE]
#handling NAs:keep only variables without NAs
training_cv <- raw_training_cv[ , colSums(is.na(raw_training_cv))==0]
#remove the first six columns of nonNA_training_cv which are row numbers and time series info
#the data analysis has no time-dependence
training_cv <- training_cv[c(-1,-2,-3,-4,-5,-6)]
#transform testing_cv and testing datasets so that they contain only variables in training_cv
testing_cv <- raw_testing_cv[ , colnames(training_cv)] #same colnames as training_cv
testing <- testing[ , colnames(training_cv[ ,-53])] #
library(randomForest)
library(rattle)
library(rpart.plot)
set.seed(12345)
Fit_trees <- train(classe~., data = training_cv, method="rpart")
fancyRpartPlot(Fit_trees$finalModel)
Prediction_trees <- predict(Fit_trees, testing_cv)
confusionMatrix(Prediction_trees, testing_cv$classe )
conf_mat <- confusionMatrix(Prediction_trees, testing_cv$classe )
conf_mat
conf_mat$overall
conf_mat$overall$accuracy
conf_mat$accuracy
conf_mat$overall.accuracy
conf_mat$overall[1]
conf_mat$overall[[1]
]
length(names(training))
#check if there are missing values
sum(is.na(training))
colnames_train <- colnames(training)
colnames_test <- colnames(testing)
all.equal(colnames_train[1:length(colnames_train)-1], colnames_test[1:length(colnames_test)-1])
library(caret)
training <- read.csv("~/Practical Machine Learning/Course_project/pml-training.csv")
testing <- read.csv("~/Practical Machine Learning/Course_project/pml-testing.csv")
#check if there are missing values
sum(is.na(training))
colnames_train <- colnames(training)
colnames_test <- colnames(testing)
all.equal(colnames_train[1:length(colnames_train)-1], colnames_test[1:length(colnames_test)-1])
inTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
raw_training_cv <- training[inTrain, ]
raw_testing_cv <- training[-inTrain,]
#remove covariates with near-zero-variablity
nzv <- nearZeroVar(raw_training_cv, saveMetrics=TRUE)
raw_training_cv <- raw_training_cv[ , nzv$nzv==FALSE]
sum(nzv$nzv==TRUE)
raw_testing_cv <- raw_testing_cv[ ,nzv$nzv==FALSE]
#Keep only variables without NAs
training_cv <- raw_training_cv[ , colSums(is.na(raw_training_cv))==0]
#remove the first six columns of raw_training_cv, which are row numbers and time series info; the data analysis has no time-dependence
training_cv <- training_cv[c(-1,-2,-3,-4,-5,-6)]
length(colnames(training_cv))
testing_cv <- raw_testing_cv[ , colnames(training_cv)] #same colnames as training_cv
testing <- testing[ , colnames(training_cv[ ,-53])]#same as training_cv w/o last column
library(randomForest)
library(rattle)
library(rpart.plot)
set.seed(12345)
Fit_trees <- train(classe~., data = training_cv, method="rpart")
fancyRpartPlot(Fit_trees$finalModel)
plot(Fit_rf)
load(file = "Fit_rf.RData", verbose = TRUE)
plot(Fit_rf)
